library(reticulate)
reticulate::repl_python()
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
path = 'data/ex1data1.txt'
data = pd.read_csv(path, header=None, names=['Population', 'Profit'])
data.head()
data.describe()
path = 'data/ex1data1.txt'
data = pd.read_csv(path, header=None, names=['Population', 'Profit'])
data.head()
data.describe()
data.plot(kind='scatter', x='Population', y='Profit', figsize=(12,8))
plt.show()
quit
library(reticulate)
reticulate::repl_python()
data.insert(0, 'Ones', 1)
data.head()
data.insert(loc=0, column='Ones', value=1)
path = 'ex1data1.txt'
data = pd.read_csv(path, header=None, names=['Population', 'Profit'])
data.head()
data.describe()
data.plot(kind='scatter', x='Population', y='Profit', figsize=(12,8))
plt.show()
data.insert(loc=0, column='Ones', value=1)
data.head()
quit
library(reticulate)
reticulate::repl_python()
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
path = 'data/ex1data1.txt'
data = pd.read_csv(path, header=None, names=['Population', 'Profit'])
data.head()
data.describe()
data.plot(kind='scatter', x='Population', y='Profit', figsize=(12,8))
plt.show()
data.insert(loc=0, column='Ones', value=1)
data.head()
X
path = 'data/ex1data1.txt'
data = pd.read_csv(path, header=None, names=['Population', 'Profit'])
data.head()
data.describe()
X, y = data[:, 0], data[:, 1]
X
X, y = data[:, 0], data[:, 1]
data
data[:, 0]
data
data[:, 0]
data.type
data.type()
data.dtype
data = np.loadtxt(os.path.join('data', 'ex1data1.txt'), delimiter=',')data.head()
data = np.loadtxt(os.path.join('data', 'ex1data1.txt'), delimiter=',')
from mpl_toolkits.mplot3d import Axes3D
import os
os.path.join('data', 'ex1data1.txt')
data = np.loadtxt(os.path.join('data', 'ex1data1.txt'), delimiter=',')
data
data.dtype
data.head()
data.describe()
X, y = data[:, 0], data[:, 1]
X
data
y
X.ndim
y.ndim
y.dim
y.dims
X
m = y.size
data.insert(loc=0, column='Ones', value=1)
data.head()
X = np.stack([np.ones(m), X], axis=1)
X
theta
X
theta=np.array([0.0, 0.0])
np.dot(X, theta)
X
def computeCost(X, y, theta):
# X是m x 2矩陣,theta是1 x 2矩陣,y是m x 1矩陣
m = y.size
J = 0
J = (1/(2 * m)) * np.sum(np.square(np.dot(X, theta) - y))
return J
J = computeCost(X, y, theta=np.array([0.0, 0.0]))
J
J = computeCost(X, y, theta=np.array([0.0, 0.0]))
print('With theta = [0, 0] \nCost computed = %.2f' % J)
J = computeCost(X, y, theta=np.array([0.0, 0.0]))
print('With theta = [0, 0] \nCost computed = %.2f' % J)
def computeCost(X, y, theta):
# X是m x 2矩陣,theta是1 x 2矩陣,y是m x 1矩陣
m = y.size
J = 0
h = np.dot(X, theta)
J = (1/(2 * m)) * np.sum(np.square(h - y))
return J
J = computeCost(X, y, theta=np.array([0.0, 0.0]))
print('With theta = [0, 0] \nCost computed = %.2f' % J)
theta.copy()
theta
theta = np.zeros(2)
# some gradient descent settings
iterations = 1500
alpha = 0.01
theta, J_history = gradientDescent(X ,y, theta, alpha, iterations)
quit
library(reticulate)
reticulate::repl_python()
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
data = np.loadtxt(os.path.join('data', 'ex1data1.txt'), delimiter=',')
X, y = data[:, 0], data
m = y.size
data.plot(kind='scatter', x='Population', y='Profit', figsize=(12,8))
plt.show()
X = np.stack([np.ones(m), X], axis=1)
def computeCost(X, y, theta):
# X是m x 2矩陣,theta是1 x 2矩陣,y是m x 1矩陣
m = y.size
J = 0
h = np.dot(X, theta)
J = (1/(2 * m)) * np.sum(np.square(h - y))
return J
J = computeCost(X, y, theta=np.array([0.0, 0.0]))
print('With theta = [0, 0] \nCost computed = %.2f' % J)
def gradientDescent(X, y, theta, alpha, num_iters):
m = y.shape[0]
theta = theta.copy()
J_history = []
for i in range(num_iters):
theta = theta - (alpha / m) * (np.dot(X, theta) - y).dot(X)
J_history.append(computeCost(X, y, theta))
return theta, J_history
def gradientDescent(X, y, theta, alpha, num_iters):
m = y.shape[0]
theta = theta.copy()
J_history = []
for i in range(num_iters):
theta = theta - (alpha / m) * (np.dot(X, theta) - y).dot(X)
J_history.append(computeCost(X, y, theta))
return theta, J_history
quit
library(reticulate)
reticulate::repl_python()
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
data = np.loadtxt(os.path.join('data', 'ex1data1.txt'), delimiter=',')
X, y = data[:, 0], data
m = y.size
data.plot(kind='scatter', x='Population', y='Profit', figsize=(12,8))
plt.show()
X = np.stack([np.ones(m), X], axis=1)
X = np.stack([np.ones(m), X], axis=1)
X
X = np.stack([np.ones(m), X], axis=1)
np.ones(m)
X
data = np.loadtxt(os.path.join('data', 'ex1data1.txt'), delimiter=',')
X, y = data[:, 0], data
m = y.size
X = np.stack([np.ones(m), X], axis=1)
np.ones(m)
X
X = np.stack([np.ones(m), X], axis=0)
X.shape
np.ones(m).shape
data = np.loadtxt(os.path.join('data', 'ex1data1.txt'), delimiter=',')
X, y = data[:, 0], data[:, 1]
m = y.size
m
X = np.stack([np.ones(m), X], axis=1)
def computeCost(X, y, theta):
# X是m x 2矩陣,theta是1 x 2矩陣,y是m x 1矩陣
m = y.size
J = 0
h = np.dot(X, theta)
J = (1/(2 * m)) * np.sum(np.square(h - y))
return J
J = computeCost(X, y, theta=np.array([0.0, 0.0]))
print('With theta = [0, 0] \nCost computed = %.2f' % J)
def gradientDescent(X, y, theta, alpha, num_iters):
m = y.shape[0]
theta = theta.copy()
J_history = []
for i in range(num_iters):
theta = theta - (alpha / m) * (np.dot(X, theta) - y).dot(X)
J_history.append(computeCost(X, y, theta))
return theta, J_history
def gradientDescent(X, y, theta, alpha, num_iters):
m = y.shape[0]
theta = theta.copy()
J_history = []
for i in range(num_iters):
theta = theta - (alpha / m) * (np.dot(X, theta) - y).dot(X)
J_history.append(computeCost(X, y, theta))
return theta, J_history
def gradientDescent(X, y, theta, alpha, num_iters):
m = y.shape[0]
theta = theta.copy()
J_history = []
for i in range(num_iters):
theta = theta - (alpha / m) * (np.dot(X, theta) - y).dot(X)
J_history.append(computeCost(X, y, theta))
return theta, J_history
def gradientDescent(X, y, theta, alpha, num_iters):
m = y.shape[0]
theta = theta.copy()
J_history = []
for i in range(num_iters):
theta = theta - (alpha / m) * (np.dot(X, theta) - y).dot(X)
J_history.append(computeCost(X, y, theta))
return theta, J_history
(np.dot(X, theta) - y)
(np.dot(X, theta) - y).dot(X)
X
theta
theta = np.zeros(2)
# some gradient descent settings
iterations = 1500
alpha = 0.01
theta, J_history = gradientDescent(X ,y, theta, alpha, iterations)
J_history
theta
print('Theta found by gradient descent: {:.4f}, {:.4f}'.format(*theta))
